# Simple Neural Network

A minimal neural network implementation from scratch in Python, supporting:
- Custom dense layers
- ReLU and Sigmoid activations
- Binary cross-entropy and MSE loss functions
- Optimizers: Adam, SGD, RMSprop
- Gradient checking
- Training and evaluation on the Iris dataset (binary classification)
- he and Xavier Initialization

## Features

- No deep learning frameworks required (only NumPy)
- Modular code: easy to add new layers or optimizers
- Includes data scaling, train/test split, and accuracy calculation
